{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f63baebb",
      "metadata": {
        "id": "f63baebb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install streamlit_extras\n",
        "!pip install streamlit\n",
        "!pip install joblib\n",
        "!pip install python-dotenv PyPDF2 streamlit langchain\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken\n",
        "!pip install pickle\n",
        "!pip install openai==0.28\n",
        "!pip install python-docx\n",
        "!pip install JIRA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64174939",
      "metadata": {
        "id": "64174939"
      },
      "source": [
        "Test the Text to SQL conversionCode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9b2b611d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b2b611d",
        "outputId": "f266eb86-4ccb-46d2-9ab4-aa287959f186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ChatBotInterface.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ChatBotInterface.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document\n",
        "import openpyxl\n",
        "from jira import JIRA, JIRAError\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import base64\n",
        "\n",
        "API_KEY = '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'\n",
        "embeddings_global = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
        "\n",
        "os.environ[\"JIRA_API_TOKEN\"] = \"ATATT3xFfGF0RffC8ROCQtuzGolQ10pwSK4YCrX_JDRlFYjCMoYbF46Cdtkv71k20YqJrXIjtt5EWg3LM2cATzq5okY27HgRO1NbE_sl89eFlvox0fz9aZbBnZhnog1n_CFnAKmhhuZkEVLnjfQuAiQJUwbqfOYBKZXjDPn611vtrWG48ySlRys=2C3FA0A6\"\n",
        "os.environ[\"JIRA_USERNAME\"] = \"Swapnil Gangwal\"\n",
        "os.environ[\"JIRA_INSTANCE_URL\"] = \"https://ai-crafter.atlassian.net/jira/software/projects/HACKT/pages\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# JIRA connection details (Replace with your actual details)\n",
        "jira_options = {'server': 'https://ai-crafter.atlassian.net/jira/software/projects/HACKT/pages'}\n",
        "jira_user = 'Swapnil Gangwal' #swpnl.08@gmail.com\n",
        "jira_api_token = 'ATATT3xFfGF0RffC8ROCQtuzGolQ10pwSK4YCrX_JDRlFYjCMoYbF46Cdtkv71k20YqJrXIjtt5EWg3LM2cATzq5okY27HgRO1NbE_sl89eFlvox0fz9aZbBnZhnog1n_CFnAKmhhuZkEVLnjfQuAiQJUwbqfOYBKZXjDPn611vtrWG48ySlRys=2C3FA0A6'\n",
        "jira_project_key = 'PROJECT_KEY'\n",
        "jira_issue_type = 'Task'\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_path = 'ChatBot1.png'\n",
        "\n",
        "\n",
        "def create_jira_ticket(summary, description):\n",
        "  try:\n",
        "      jira = JIRA(options=jira_options, basic_auth=(jira_user, jira_api_token))\n",
        "      issue_dict = {\n",
        "          'project': {'key': jira_project_key},\n",
        "          'summary': summary,\n",
        "          'description': description,\n",
        "          'issuetype': {'name': jira_issue_type},\n",
        "      }\n",
        "      new_issue = jira.create_issue(fields=issue_dict)\n",
        "      return new_issue.key\n",
        "  except JIRAError as e:\n",
        "      print(f\"Failed to create JIRA ticket: {e}\")\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      # This catches other unforeseen exceptions\n",
        "      print(f\"An unexpected error occurred: {e}\")\n",
        "      return None\n",
        "\n",
        "def process_text(text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
        "    knowledgeBase = FAISS.from_texts(chunks, embeddings)\n",
        "    return knowledgeBase\n",
        "\n",
        "# Functions to read PDF, DOCX, and XLSX files remain the same\n",
        "def read_pdf(file):\n",
        "    pdf_reader = PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in pdf_reader.pages:\n",
        "        text += page.extract_text() or \"\"  # Fallback to empty string if None\n",
        "    return text\n",
        "\n",
        "def read_docx(file):\n",
        "    doc = Document(file)\n",
        "    text = \"\"\n",
        "    for para in doc.paragraphs:\n",
        "        text += para.text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def read_xlsx(file):\n",
        "    wb = openpyxl.load_workbook(file)\n",
        "    text = \"\"\n",
        "    for sheet in wb:\n",
        "        for row in sheet.iter_rows(values_only=True):\n",
        "            if row:\n",
        "                text += \" \".join([str(cell) for cell in row if cell is not None]) + \"\\n\"\n",
        "    return text\n",
        "def main():\n",
        "    # CSS to inject contained in a multi-line string\n",
        "    background = \"\"\"\n",
        "        <style>\n",
        "        h1 {\n",
        "            color: #ADD8E6;\n",
        "        }\n",
        "        .stTextInput>div>div>input {\n",
        "            color: black;\n",
        "        }\n",
        "        .stButton>button {\n",
        "            border: 2px solid #ADD8E6; /* Light Blue */\n",
        "            background-color: #ADD8E6; /* Light Blue */\n",
        "            color: white;\n",
        "            padding: 10px 24px;\n",
        "            cursor: pointer;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        .stButton>button:hover {\n",
        "            background-color: #BFEFFF; /* Lighter Blue */\n",
        "            color: white;\n",
        "        }\n",
        "        </style>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    st.markdown(background, unsafe_allow_html=True)\n",
        "    st.markdown(\"# AI Crafters' ðŸ’¬\")\n",
        "    st.image(image_path, width=700)\n",
        "\n",
        "    uploaded_files = st.file_uploader('Upload your document(s)', type=['pdf', 'docx', 'xlsx'], accept_multiple_files=True)\n",
        "\n",
        "    text = \"\"\n",
        "    if uploaded_files:\n",
        "        for uploaded_file in uploaded_files:\n",
        "            if uploaded_file.type == \"application/pdf\":\n",
        "                text += read_pdf(uploaded_file)\n",
        "            elif uploaded_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "                text += read_docx(uploaded_file)\n",
        "            elif uploaded_file.type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
        "                text += read_xlsx(uploaded_file)\n",
        "\n",
        "        knowledgeBase = process_text(text)\n",
        "\n",
        "        query = st.text_input('Ask a question to the document(s)')\n",
        "        cancel_button = st.button('Cancel')\n",
        "\n",
        "        if cancel_button:\n",
        "            st.stop()\n",
        "        no_answer = [\"i'm sorry\", \"i don't know\", \"i don't know what\",\"I do not know,+\"]\n",
        "        if query:\n",
        "            docs = knowledgeBase.similarity_search(query)\n",
        "            llm = OpenAI(openai_api_key=API_KEY)\n",
        "            chain = load_qa_chain(llm, chain_type='stuff')\n",
        "\n",
        "            with get_openai_callback() as cost:\n",
        "                response = chain.run(input_documents=docs, question=query)\n",
        "\n",
        "            if not response or 'no answer found' in response.lower() or any(substring in response.lower() for substring in no_answer):\n",
        "              st.write(\"No answer found. Would you like to raise a JIRA ticket?\")\n",
        "              col1, col2 = st.columns(2)  # Create two columns for Yes and No buttons\n",
        "              if col1.button('Yes'):\n",
        "                  ticket_id = create_jira_ticket(\n",
        "                      summary=f\"Query unanswered: {query[:50]}...\",  # Truncate query to fit summary\n",
        "                      description=f\"A query made to documents did not return an answer: {query}\\n\\nPlease investigate.\"\n",
        "                  )\n",
        "                  st.success(f\"JIRA ticket created successfully: {ticket_id}\")\n",
        "              elif col2.button('No'):\n",
        "                  st.info(\"You chose not to raise a JIRA ticket.\")\n",
        "            else:\n",
        "                st.write(response)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!rm -f /content/checklogs.txt && streamlit run ChatBotInterface.py &> /content/checklogs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw7vvWDYZelX",
        "outputId": "86b54f94-a9b9-404c-cd90-365b75c8ad4d"
      },
      "id": "Bw7vvWDYZelX",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.185.21.216\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.508s\n",
            "your url is: https://hungry-dolls-glow.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile queryText.py\n",
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "import os\n",
        "\n",
        "from util import *\n",
        "\n",
        "from prompt_txn import *\n",
        "import string  # Add this line to import the string module\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "import openai\n",
        "from prompt_txn import query_prompt_txn  # Import the custom function from your prompt.py\n",
        "from prompt_txn import *\n",
        "import string\n",
        "\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "MODEL = \"gpt-3.5-turbo\"\n",
        "#llm = OpenAI(model_name=MODEL, temperature=0)\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "df = pd.read_csv('TxnDetails.csv')\n",
        "df['Transaction_date'] = pd.to_datetime(df['Transaction_date'])\n",
        "df['Benename'] = df['Benename'].str.lower()\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you've already set your API key in the environment\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Define the question\n",
        "question = 'Details of Failed Transactions'\n",
        "\n",
        "# Use the custom function to format the question for the AI\n",
        "formatted_prompt = query_prompt_txn.format(question=question)\n",
        "\n",
        "# Structure the messages for the chat completion API\n",
        "messages = [\n",
        "   # {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides information about commodities.\"},\n",
        "    {\"role\": \"user\", \"content\": formatted_prompt}\n",
        "]\n",
        "#llm(query_prompt_txn.format(question=question))\n",
        "# Attempt to make the API request\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=MODEL,\n",
        "        messages=messages\n",
        "    )\n",
        "    # Extract and print the generated output\n",
        "    llm_out = response.choices[0].message['content']  # Correctly access the message content\n",
        "    print(\"=================================Code Generated==================================\")\n",
        "    print(llm_out)\n",
        "    print(\"=================================================================================\\n\")\n",
        "\n",
        "    # If llm_out contains code, review it carefully before execution\n",
        "    # Safety Note: Directly executing code without reviewing can be risky\n",
        "    _        = print(llm_out)\n",
        "    _        =exec(llm_out)\n",
        "    # If the code defines a function `func`, you can call it here\n",
        "    answer = func()\n",
        "    answer\n",
        "    print(answer)\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", str(e))\n",
        "print(\"=================================ExecutedSample==================================\")\n",
        "\n",
        "def textToSQL(question):\n",
        "    formatted_prompt = query_prompt_txn.format(question=question)\n",
        "    messages1 = [\n",
        "        {\"role\": \"user\", \"content\": formatted_prompt}\n",
        "    ]\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=messages1,\n",
        "            messages=messages\n",
        "        )\n",
        "        llm_out = response.choices[0].message['content']\n",
        "        print(\"=================================Code Generated==================================\")\n",
        "        print(llm_out)\n",
        "        print(\"=================================================================================\\n\")\n",
        "\n",
        "        # Dynamically execute the generated code.\n",
        "        # WARNING: Executing code like this can be dangerous if you're not sure about the code's safety.\n",
        "        # Ensure the generated code is safe before executing.\n",
        "        local_vars = {}\n",
        "        exec(llm_out, {'df': df}, local_vars)\n",
        "        answer = local_vars.get('answer')  # Assuming the generated code assigns output to 'answer'\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", str(e))\n",
        "        return None\n",
        "\n",
        "def process_documents_and_answer_question(documents, question):\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    document_objects = []\n",
        "\n",
        "    for document_text in documents:\n",
        "        chunks = text_splitter.split_text(document_text)\n",
        "        document_objects.extend([DocumentObject(chunk) for chunk in chunks])\n",
        "\n",
        "    embeddings = CustomOpenAIEmbeddings(API_KEY)\n",
        "    db = Chroma.from_documents(document_objects, embeddings)\n",
        "\n",
        "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
        "\n",
        "    qa = RetrievalQA.from_chain_type(llm=OpenAI(api_key=API_KEY), chain_type=\"base\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "    result = qa({\"query\": question})\n",
        "    return result\n",
        "\n",
        "# Modify the `exec` usage to match how results are generated\n",
        "def textToSQL1(question, documents):\n",
        "    formatted_prompt = query_prompt_txn.format(question=question)\n",
        "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=MODEL, messages=messages)\n",
        "        llm_out = response.choices[0].message['content']\n",
        "\n",
        "        local_vars = {'df': documents}  # Pass 'documents' DataFrame as 'df'\n",
        "        exec(llm_out, globals(), local_vars)\n",
        "\n",
        "        # Adjust this line based on how 'llm_out' assigns or returns its result\n",
        "        answer = local_vars.get('func')()  # If 'func' returns the desired result\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "print(textToSQL1(\"Details of SUCCESS Transactions\",df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yOIP0kOqomg",
        "outputId": "be6487d5-1dee-4240-bdd5-7ae8a8aa7670"
      },
      "id": "3yOIP0kOqomg",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================Code Generated==================================\n",
            "def func():\n",
            "    failed_df = df[df['Payment_status'] == 'Failed']\n",
            "    return failed_df[['Transaction_id', 'User_id', 'Amount', 'Currency', 'Description', 'CountryCode', 'Benename']]\n",
            "=================================================================================\n",
            "\n",
            "def func():\n",
            "    failed_df = df[df['Payment_status'] == 'Failed']\n",
            "    return failed_df[['Transaction_id', 'User_id', 'Amount', 'Currency', 'Description', 'CountryCode', 'Benename']]\n",
            "   Transaction_id  User_id   Amount Currency Description CountryCode Benename\n",
            "4         6357658  UYT5735  32000.0      INR        Self       china  madhuri\n",
            "9         8875693  WER4537   5000.0      INR        Self       japan  pushkar\n",
            "=================================ExecutedSample==================================\n",
            "   Transaction_id   User_id   Amount Currency Description    CountryCode  \\\n",
            "0         6352732   HJG5735   2000.0      INR        SELF           peru   \n",
            "1         5635286   YUL9853  12000.0      INR        Bill        morocco   \n",
            "2         6358931   QWE0835  20000.0      INR       Paytm  united states   \n",
            "3         6352875  HUYH5735   2000.0      INR        SELF    new zealand   \n",
            "5         6374648   HJG5735   2000.0      INR        SELF         brazil   \n",
            "6         5374843   POI9853  24452.0      INR        Rent          spain   \n",
            "7          883938   ERT0835  23532.0      INR       Paytm         brazil   \n",
            "8          264894   MJK9087   2223.0      INR        SELF         canada   \n",
            "\n",
            "  Benename  \n",
            "0   mahima  \n",
            "1     ranu  \n",
            "2     renu  \n",
            "3  swapnil  \n",
            "5  shradha  \n",
            "6    rohan  \n",
            "7   chetan  \n",
            "8    vinit  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile queryText.py\n",
        "import os\n",
        "import streamlit as st\n",
        "\n",
        "from util import *\n",
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "from prompt_txn import *\n",
        "import string  # Add this line to import the string module\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "\n",
        "image_path = 'ChatBot1.png'\n",
        "openai.api_key = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "MODEL = \"gpt-3.5-turbo\"\n",
        "llm = OpenAI(model_name=MODEL, temperature=0)\n",
        "\n",
        "df = pd.read_csv('TxnDetails.csv')\n",
        "df['Transaction_date'] = pd.to_datetime(df['Transaction_date'])\n",
        "df['Benename'] = df['Benename'].str.lower()\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def process_documents_and_answer_question(documents, question):\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    document_objects = []\n",
        "\n",
        "    for document_text in documents:\n",
        "        chunks = text_splitter.split_text(document_text)\n",
        "        document_objects.extend([DocumentObject(chunk) for chunk in chunks])\n",
        "\n",
        "    embeddings = CustomOpenAIEmbeddings(API_KEY)\n",
        "    db = Chroma.from_documents(document_objects, embeddings)\n",
        "\n",
        "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
        "\n",
        "    qa = RetrievalQA.from_chain_type(llm=OpenAI(api_key=API_KEY), chain_type=\"base\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "    result = qa({\"query\": question})\n",
        "    return result\n",
        "\n",
        "# Modify the `exec` usage to match how results are generated\n",
        "def textToSQL(question, documents):\n",
        "    formatted_prompt = query_prompt_txn.format(question=question)\n",
        "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=MODEL, messages=messages)\n",
        "        llm_out = response.choices[0].message['content']\n",
        "\n",
        "        local_vars = {'df': documents}  # Pass 'documents' DataFrame as 'df'\n",
        "        exec(llm_out, globals(), local_vars)\n",
        "\n",
        "        # Adjust this line based on how 'llm_out' assigns or returns its result\n",
        "        answer = local_vars.get('func')()  # If 'func' returns the desired result\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def main():\n",
        "     # CSS to inject contained in a multi-line string\n",
        "    background = \"\"\"\n",
        "        <style>\n",
        "        h1 {\n",
        "            color: #ADD8E6;\n",
        "        }\n",
        "        .stTextInput>div>div>input {\n",
        "            color: black;\n",
        "        }\n",
        "        .stButton>button {\n",
        "            border: 2px solid #ADD8E6; /* Light Blue */\n",
        "            background-color: #ADD8E6; /* Light Blue */\n",
        "            color: white;\n",
        "            padding: 10px 24px;\n",
        "            cursor: pointer;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        .stButton>button:hover {\n",
        "            background-color: #BFEFFF; /* Lighter Blue */\n",
        "            color: white;\n",
        "        }\n",
        "        </style>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    st.markdown(background, unsafe_allow_html=True)\n",
        "    st.markdown(\"# AI Crafters' ðŸ’¬\")\n",
        "    st.image(image_path, width=700)\n",
        "    st.title(\"Transaction Query Processor\")\n",
        "    questionAsk = st.text_input(\"Enter your transaction query:\", \"\")\n",
        "\n",
        "    if st.button(\"Process Query\"):\n",
        "      if questionAsk:\n",
        "          # Call the textToSQL function with the question and df\n",
        "          try:\n",
        "              reply = textToSQL(questionAsk,df)\n",
        "              if reply is not None:\n",
        "                  # Display the answer\n",
        "                  st.success(\"Query processed successfully.\")\n",
        "                  st.write(reply)\n",
        "              else:\n",
        "                  st.error(\"No answer could be generated for the query.\")\n",
        "          except Exception as e:\n",
        "              st.error(f\"An error occurred: {str(e)}\")\n",
        "      else:\n",
        "          st.error(\"Please enter a query to process.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huMxthA7r2-i",
        "outputId": "50b2d7da-38fc-4cda-d8cf-e454c0c46868"
      },
      "id": "huMxthA7r2-i",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting queryText.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!rm -f /content/checkqueryTextlogs.txt && streamlit run queryText.py &> /content/checkqueryTextlogs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbdGknwQqwo1",
        "outputId": "a57b9b25-50c2-41c8-cf95-f64e1d6d0f08"
      },
      "id": "mbdGknwQqwo1",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.185.21.216\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.058s\n",
            "your url is: https://tame-spies-talk.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ChatBotInterfaceCombined.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document\n",
        "import openpyxl\n",
        "from jira import JIRA, JIRAError\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import base64\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "from util import *\n",
        "import openai\n",
        "from prompt_txn import *\n",
        "\n",
        "\n",
        "API_KEY = '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'\n",
        "embeddings_global = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "\n",
        "os.environ[\"JIRA_API_TOKEN\"] = \"ATATT3xFfGF0RffC8ROCQtuzGolQ10pwSK4YCrX_JDRlFYjCMoYbF46Cdtkv71k20YqJrXIjtt5EWg3LM2cATzq5okY27HgRO1NbE_sl89eFlvox0fz9aZbBnZhnog1n_CFnAKmhhuZkEVLnjfQuAiQJUwbqfOYBKZXjDPn611vtrWG48ySlRys=2C3FA0A6\"\n",
        "os.environ[\"JIRA_USERNAME\"] = \"Swapnil Gangwal\"\n",
        "os.environ[\"JIRA_INSTANCE_URL\"] = \"https://ai-crafter.atlassian.net/jira/software/projects/HACKT/pages\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# JIRA connection details (Replace with your actual details)\n",
        "jira_options = {'server': 'https://ai-crafter.atlassian.net/jira/software/projects/HACKT/pages'}\n",
        "jira_user = 'Swapnil Gangwal' #swpnl.08@gmail.com\n",
        "jira_api_token = 'ATATT3xFfGF0RffC8ROCQtuzGolQ10pwSK4YCrX_JDRlFYjCMoYbF46Cdtkv71k20YqJrXIjtt5EWg3LM2cATzq5okY27HgRO1NbE_sl89eFlvox0fz9aZbBnZhnog1n_CFnAKmhhuZkEVLnjfQuAiQJUwbqfOYBKZXjDPn611vtrWG48ySlRys=2C3FA0A6'\n",
        "jira_project_key = 'HACKT'\n",
        "jira_issue_type = 'Task'\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_path = 'ChatBot1.png'\n",
        "\n",
        "\n",
        "def create_jira_ticket(summary, description):\n",
        "  try:\n",
        "      jira = JIRA(options=jira_options, basic_auth=(jira_user, jira_api_token))\n",
        "      issue_dict = {\n",
        "          'project': {'key': jira_project_key},\n",
        "          'summary': summary,\n",
        "          'description': description,\n",
        "          'issuetype': {'name': jira_issue_type},\n",
        "      }\n",
        "      new_issue = jira.create_issue(fields=issue_dict)\n",
        "      return new_issue.key\n",
        "  except JIRAError as e:\n",
        "      print(f\"Failed to create JIRA ticket: {e}\")\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      # This catches other unforeseen exceptions\n",
        "      print(f\"An unexpected error occurred: {e}\")\n",
        "      return None\n",
        "\n",
        "def process_text(text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
        "    knowledgeBase = FAISS.from_texts(chunks, embeddings)\n",
        "    return knowledgeBase\n",
        "\n",
        "# Functions to read PDF, DOCX, and XLSX files remain the same\n",
        "def read_pdf(file):\n",
        "    pdf_reader = PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in pdf_reader.pages:\n",
        "        text += page.extract_text() or \"\"  # Fallback to empty string if None\n",
        "    return text\n",
        "\n",
        "def read_docx(file):\n",
        "    doc = Document(file)\n",
        "    text = \"\"\n",
        "    for para in doc.paragraphs:\n",
        "        text += para.text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def read_xlsx(file):\n",
        "    wb = openpyxl.load_workbook(file)\n",
        "    text = \"\"\n",
        "    for sheet in wb:\n",
        "        for row in sheet.iter_rows(values_only=True):\n",
        "            if row:\n",
        "                text += \" \".join([str(cell) for cell in row if cell is not None]) + \"\\n\"\n",
        "    return text\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "MODEL = \"gpt-3.5-turbo\"\n",
        "# Modify the `exec` usage to match how results are generated\n",
        "def textToSQL(question, documents):\n",
        "    if documents.empty:\n",
        "       # print(\"DataFrame is empty.\")\n",
        "        return \"DataFrame is empty, unable to process the query.\"\n",
        "\n",
        "    #llm = OpenAI(model_name=MODEL, temperature=0)\n",
        "    formatted_prompt = query_prompt_txn.format(question=question)\n",
        "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "\n",
        "    try:\n",
        "      response = openai.ChatCompletion.create(model=MODEL, messages=messages)\n",
        "      llm_out = response.choices[0].message['content']\n",
        "\n",
        "      local_vars = {'df': documents}  # Pass 'documents' DataFrame as 'df'\n",
        "      exec(llm_out, globals(), local_vars)\n",
        "\n",
        "      # Adjust this line based on how 'llm_out' assigns or returns its result\n",
        "      answer = local_vars.get('func')()  # If 'func' returns the desired result\n",
        "      return answer\n",
        "    except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "      return None\n",
        "\n",
        "def textToSQL_1(question, documents):\n",
        "    formatted_prompt = query_prompt_txn.format(question=question)\n",
        "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
        "        llm_out = response.choices[0].message['content']\n",
        "\n",
        "        st.write(\"Generated Code:\", llm_out)  # Display the generated code in Streamlit\n",
        "\n",
        "        local_vars = {'df': documents}\n",
        "        exec(llm_out, globals(), local_vars)  # Execute the generated code\n",
        "\n",
        "        if 'func' in local_vars:\n",
        "            answer = local_vars['func']()  # Call the dynamically defined function\n",
        "            st.write(\"Answer:\", answer)  # Display the answer in Streamlit\n",
        "            return answer\n",
        "        else:\n",
        "            st.write(\"Function 'func' not defined.\")\n",
        "    except Exception as e:\n",
        "        st.write(f\"An error occurred: {e}\")\n",
        "    return None\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def main():\n",
        "    # CSS to inject contained in a multi-line string\n",
        "    background = \"\"\"\n",
        "        <style>\n",
        "        h1 {\n",
        "            color: #ADD8E6;\n",
        "        }\n",
        "        .stTextInput>div>div>input {\n",
        "            color: black;\n",
        "        }\n",
        "        .stButton>button {\n",
        "            border: 2px solid #ADD8E6; /* Light Blue */\n",
        "            background-color: #ADD8E6; /* Light Blue */\n",
        "            color: white;\n",
        "            padding: 10px 24px;\n",
        "            cursor: pointer;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        .stButton>button:hover {\n",
        "            background-color: #BFEFFF; /* Lighter Blue */\n",
        "            color: white;\n",
        "        }\n",
        "        </style>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    st.markdown(background, unsafe_allow_html=True)\n",
        "    st.markdown(\"# AI Crafters' ðŸ’¬\")\n",
        "    st.image(image_path, width=700)\n",
        "\n",
        "    uploaded_files = st.file_uploader('Upload your document(s)', type=['pdf', 'docx', 'xlsx'], accept_multiple_files=True)\n",
        "\n",
        "    text = \"\"\n",
        "    if uploaded_files:\n",
        "        for uploaded_file in uploaded_files:\n",
        "            if uploaded_file.type == \"application/pdf\":\n",
        "                text += read_pdf(uploaded_file)\n",
        "            elif uploaded_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "                text += read_docx(uploaded_file)\n",
        "            elif uploaded_file.type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
        "                text += read_xlsx(uploaded_file)\n",
        "\n",
        "        knowledgeBase = process_text(text)\n",
        "\n",
        "        query = st.text_input('Ask a question to the document(s)')\n",
        "        cancel_button = st.button('Cancel')\n",
        "\n",
        "        if cancel_button:\n",
        "            st.stop()\n",
        "        no_answer = [\"i'm sorry\", \"i don't know\", \"i don't know what\",\"I do not know,+\"]\n",
        "        if query:\n",
        "            docs = knowledgeBase.similarity_search(query)\n",
        "            llm = OpenAI(openai_api_key=API_KEY)\n",
        "            chain = load_qa_chain(llm, chain_type='stuff')\n",
        "\n",
        "            with get_openai_callback() as cost:\n",
        "                response = chain.run(input_documents=docs, question=query)\n",
        "\n",
        "            if not response or 'no answer found' in response.lower() or any(substring in response.lower() for substring in no_answer):\n",
        "              st.write(\"No answer found. Would you like to raise a JIRA ticket?\")\n",
        "              col1, col2 = st.columns(2)  # Create two columns for Yes and No buttons\n",
        "              if col1.button('Yes'):\n",
        "                  ticket_id = create_jira_ticket(\n",
        "                      summary=f\"Query unanswered: {query[:50]}...\",  # Truncate query to fit summary\n",
        "                      description=f\"A query made to documents did not return an answer: {query}\\n\\nPlease investigate.\"\n",
        "                  )\n",
        "                  st.success(f\"JIRA ticket created successfully: {ticket_id}\")\n",
        "              elif col2.button('No'):\n",
        "                  st.info(\"You chose not to raise a JIRA ticket.\")\n",
        "            else:\n",
        "                st.write(response)\n",
        "    st.title(\"Transaction Query Processor\")\n",
        "    uploaded_df_file = st.file_uploader(\"Upload CSV for Transaction Details\", type=['csv'])\n",
        "    df = pd.DataFrame()\n",
        "    if uploaded_df_file is not None:\n",
        "        # Load the uploaded CSV into a DataFrame\n",
        "        df = pd.read_csv(uploaded_df_file)\n",
        "        if not df.empty:\n",
        "          st.write(\"Uploaded DataFrame:\", df.head())\n",
        "        else:\n",
        "          st.error(\"No DataFrame uploaded.\")\n",
        "\n",
        "    questionAsk = st.text_input(\"Enter your transaction query:\", \"\")\n",
        "\n",
        "    if st.button(\"Process Query\") and not df.empty:\n",
        "        # Ensure 'df' is not empty before processing the query\n",
        "        try:\n",
        "            reply = textToSQL_1(questionAsk, df)\n",
        "\n",
        "            if reply is not None:\n",
        "                # Display the answer\n",
        "                st.success(\"Query processed successfully.\")\n",
        "                st.write(reply)\n",
        "            else:\n",
        "                st.error(\"No answer could be generated for the query.\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred: {str(e)}\")\n",
        "    elif df.empty:\n",
        "        st.error(\"Please upload a CSV file for transaction details.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzoXGKar4fZc",
        "outputId": "c4dc1f5b-598a-4fed-a15d-3c88eb7e90a9"
      },
      "id": "SzoXGKar4fZc",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ChatBotInterfaceCombined.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!rm -f /content/ChatBotInterfaceCombinedlogs.txt && streamlit run ChatBotInterfaceCombined.py &> /content/ChatBotInterfaceCombinedtlogs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqSbYVP-4jCV",
        "outputId": "249c769c-d247-4d0e-cc54-aa30493054b8"
      },
      "id": "ZqSbYVP-4jCV",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.185.21.216\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.16s\n",
            "your url is: https://fast-nails-chew.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document\n",
        "import openpyxl\n",
        "from jira import JIRA, JIRAError\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import base64\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "from util import *\n",
        "import openai\n",
        "from prompt_txn import *\n",
        "\n",
        "API_KEY = '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'\n",
        "embeddings_global = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "df = pd.read_csv('TxnDetails.csv')\n",
        "df['Transaction_date'] = pd.to_datetime(df['Transaction_date'])\n",
        "df['Benename'] = df['Benename'].str.lower()\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "# Modify the `exec` usage to match how results are generated\n",
        "def textToSQL(question, documents):\n",
        "    MODEL = \"gpt-3.5-turbo\"\n",
        "    #llm = OpenAI(model_name=MODEL, temperature=0)\n",
        "    formatted_prompt = query_prompt_txn.format(question=question)\n",
        "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=MODEL, messages=messages)\n",
        "        llm_out = response.choices[0].message['content']\n",
        "\n",
        "        local_vars = {'df': documents}  # Pass 'documents' DataFrame as 'df'\n",
        "        exec(llm_out, globals(), local_vars)\n",
        "\n",
        "        # Adjust this line based on how 'llm_out' assigns or returns its result\n",
        "        answer = local_vars.get('func')()  # If 'func' returns the desired result\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "def textToSQL_1(question, documents):\n",
        "    formatted_prompt = query_prompt_txn.format(question=question)\n",
        "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
        "        llm_out = response.choices[0].message['content']\n",
        "        print(\"Generated Code:\", llm_out)  # Check the generated code\n",
        "\n",
        "        local_vars = {'df': documents}\n",
        "        exec(llm_out, globals(), local_vars)  # Execute the generated code\n",
        "\n",
        "        if 'func' in local_vars:\n",
        "            answer = local_vars['func']()  # Call the dynamically defined function\n",
        "            print(\"Answer:\", answer)\n",
        "            return answer\n",
        "        else:\n",
        "            print(\"Function 'func' not defined.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "print(textToSQL_1(\"Details of SUCCESS Transactions\",df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyhcAHft8sta",
        "outputId": "b9306cab-ee20-475e-9a8e-abb64a78c1b8"
      },
      "id": "ZyhcAHft8sta",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code: def func():\n",
            "    success_df = df[df['Payment_status'] == 'SUCCESS']\n",
            "    return success_df[['Transaction_id', 'User_id', 'Amount', 'Currency', 'Description', 'CountryCode', 'Benename']]\n",
            "Answer:    Transaction_id   User_id   Amount Currency Description    CountryCode  \\\n",
            "0         6352732   HJG5735   2000.0      INR        SELF           peru   \n",
            "1         5635286   YUL9853  12000.0      INR        Bill        morocco   \n",
            "2         6358931   QWE0835  20000.0      INR       Paytm  united states   \n",
            "3         6352875  HUYH5735   2000.0      INR        SELF    new zealand   \n",
            "5         6374648   HJG5735   2000.0      INR        SELF         brazil   \n",
            "6         5374843   POI9853  24452.0      INR        Rent          spain   \n",
            "7          883938   ERT0835  23532.0      INR       Paytm         brazil   \n",
            "8          264894   MJK9087   2223.0      INR        SELF         canada   \n",
            "\n",
            "  Benename  \n",
            "0   mahima  \n",
            "1     ranu  \n",
            "2     renu  \n",
            "3  swapnil  \n",
            "5  shradha  \n",
            "6    rohan  \n",
            "7   chetan  \n",
            "8    vinit  \n",
            "   Transaction_id   User_id   Amount Currency Description    CountryCode  \\\n",
            "0         6352732   HJG5735   2000.0      INR        SELF           peru   \n",
            "1         5635286   YUL9853  12000.0      INR        Bill        morocco   \n",
            "2         6358931   QWE0835  20000.0      INR       Paytm  united states   \n",
            "3         6352875  HUYH5735   2000.0      INR        SELF    new zealand   \n",
            "5         6374648   HJG5735   2000.0      INR        SELF         brazil   \n",
            "6         5374843   POI9853  24452.0      INR        Rent          spain   \n",
            "7          883938   ERT0835  23532.0      INR       Paytm         brazil   \n",
            "8          264894   MJK9087   2223.0      INR        SELF         canada   \n",
            "\n",
            "  Benename  \n",
            "0   mahima  \n",
            "1     ranu  \n",
            "2     renu  \n",
            "3  swapnil  \n",
            "5  shradha  \n",
            "6    rohan  \n",
            "7   chetan  \n",
            "8    vinit  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}